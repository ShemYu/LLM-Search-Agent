{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai                        0.27.9\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = config(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci\n",
      "text-davinci-001\n",
      "text-search-curie-query-001\n",
      "gpt-3.5-turbo\n",
      "babbage\n",
      "text-babbage-001\n",
      "curie-instruct-beta\n",
      "davinci-similarity\n",
      "code-davinci-edit-001\n",
      "text-similarity-curie-001\n",
      "ada-code-search-text\n",
      "gpt-3.5-turbo-0613\n",
      "text-search-ada-query-001\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-4-0314\n",
      "babbage-search-query\n",
      "ada-similarity\n",
      "text-curie-001\n",
      "gpt-4\n",
      "gpt-3.5-turbo-16k\n",
      "text-search-ada-doc-001\n",
      "text-search-babbage-query-001\n",
      "code-search-ada-code-001\n",
      "curie-search-document\n",
      "davinci-002\n",
      "text-search-davinci-query-001\n",
      "text-search-curie-doc-001\n",
      "babbage-search-document\n",
      "babbage-002\n",
      "babbage-code-search-text\n",
      "text-embedding-ada-002\n",
      "davinci-instruct-beta\n",
      "davinci-search-query\n",
      "text-similarity-babbage-001\n",
      "text-davinci-002\n",
      "code-search-babbage-text-001\n",
      "text-davinci-003\n",
      "text-search-davinci-doc-001\n",
      "code-search-ada-text-001\n",
      "ada-search-query\n",
      "text-similarity-ada-001\n",
      "gpt-4-0613\n",
      "ada-code-search-code\n",
      "whisper-1\n",
      "text-davinci-edit-001\n",
      "davinci-search-document\n",
      "curie-search-query\n",
      "babbage-similarity\n",
      "ada\n",
      "ada-search-document\n",
      "text-ada-001\n",
      "text-similarity-davinci-001\n",
      "curie-similarity\n",
      "babbage-code-search-code\n",
      "code-search-babbage-code-001\n",
      "text-search-babbage-doc-001\n",
      "gpt-3.5-turbo-0301\n",
      "curie\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "for model in openai.Model.list()[\"data\"]:\n",
    "    print(model[\"id\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", # Good model with a high cost-to-performance ratio.\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"請幫我寫一篇關於 fintech 的簡介\"\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fintech，即金融科技，是指利用先進的科技和創新的方法，改變和提升金融服務的交付和使用方式。它集成了金融和技術領域的專業知識，致力於打造更簡便、高效、智能和安全的金融體驗。\n",
      "\n",
      "傳統上，金融服務通常由傳統銀行和金融機構提供，需要人們去分行辦理業務或使用其他傳統的方式進行操作。然而，隨著科技的發展和數字化時代的來臨，Fintech應運而生，為人們帶來了更多便利和選擇。\n",
      "\n",
      "Fintech的應用領域廣泛\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content) # 回應受限於 Token 數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1161c52b0> JSON: {\n",
       "  \"prompt_tokens\": 29,\n",
       "  \"completion_tokens\": 256,\n",
       "  \"total_tokens\": 285\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage # Cost checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Please play a role as English expert, correct my spelling and grammar.  Response template should be json type as following template \\{'res':<your_response>\\}\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I really good coding, I programer!\"\n",
    "    },\n",
    "  ],\n",
    "  n = 3, # How many response will be generate\n",
    "  max_tokens=1000, # maximal of the token\n",
    "  temperature=0, # Higher values will make the output more random, lower values will make it more focused and deterministic\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API parameters\n",
    "[OpenAI - Create chat completion](https://platform.openai.com/docs/api-reference/chat/create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result \n",
    "\n",
    "Due to the low temperature, the response is stable and the output follows the specified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'res': \"I am really good at coding. I am a programmer!\"}\n"
     ]
    }
   ],
   "source": [
    "print(response2.choices[0].message.content) # Response 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'res': \"I am really good at coding. I am a programmer!\"}\n"
     ]
    }
   ],
   "source": [
    "print(response2.choices[1].message.content) # Response 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'res': \"I am really good at coding. I am a programmer!\"}\n"
     ]
    }
   ],
   "source": [
    "print(response2.choices[2].message.content) # Response 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x11625dd30> JSON: {\n",
       "  \"prompt_tokens\": 53,\n",
       "  \"completion_tokens\": 51,\n",
       "  \"total_tokens\": 104\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.usage # Cost checking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Although the performance is quite good and stable in individual tests, the OpenAI module interface is not intuitive or easy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
